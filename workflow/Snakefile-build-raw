"""
Snakefile for doing the first stages of data processing from the daq sandbox files
to the blinded raw data. It handles:
- moving the daq files from the sandbox to the sorted file system
- running build raw on this data (with trimming)
- blinding the physics data
"""

import os, sys
from pathlib import Path
from legenddataflow import patterns as patt
from legenddataflow import utils, execenv, ParsKeyResolve
from datetime import datetime
from dbetto import AttrsDict
from legendmeta import LegendMetadata

utils.subst_vars_in_snakemake_config(workflow, config)
config = AttrsDict(config)

check_in_cycle = True
swenv = execenv.execenv_prefix(config)
meta_path = utils.metadata_path(config)
det_status = utils.det_status_path(config)
configs = utils.config_path(config)
chan_maps = utils.chan_map_path(config)
meta = utils.metadata_path(config)

time = datetime.now().strftime("%Y%m%dT%H%M%SZ")

# NOTE: this will attempt a clone of legend-metadata, if the directory does not exist
metadata = LegendMetadata(meta_path, lazy=True)
if "legend_metadata_version" in config:
    metadata.checkout(config.legend_metadata_version)


wildcard_constraints:
    experiment=r"\w+",
    period=r"p\d{2}",
    run=r"r\d{3}",
    datatype=r"\w{3}",
    timestamp=r"\d{8}T\d{6}Z",


localrules:
    gen_filelist,
    autogen_output,


include: "rules/common.smk"
include: "rules/filelist_gen.smk"
include: "rules/main.smk"
include: "rules/raw.smk"
include: "rules/blinding_check.smk"


onstart:
    print("INFO: initializing workflow")

    # Make sure some packages are initialized before we send jobs to avoid race conditions
    if not workflow.touch:
        shell(
            execenv.execenv_pyexe(config, "python") + " -c 'import daq2lh5, matplotlib'"
        )

    raw_par_cat_file = Path(utils.pars_path(config)) / "raw" / "validity.yaml"
    if raw_par_cat_file.is_file():
        raw_par_cat_file.unlink()
    try:
        Path(raw_par_cat_file).parent.mkdir(parents=True, exist_ok=True)
        raw_par_catalog.write_to(raw_par_cat_file)
    except NameError:
        print("WARNING: no raw parameter catalog found")


onsuccess:
    shell("rm -f *.gen")
    shell(f"rm -rf {utils.filelist_path(config)}/*")


rule gen_filelist:
    input:
        lambda wildcards: get_filelist(
            wildcards,
            config,
            get_search_pattern(wildcards.tier),
            ignore_keys_file=Path(det_status) / "ignored_daq_cycles.yaml",
            analysis_runs_file=Path(det_status) / "runlists.yaml",
        ),
    output:
        temp(Path(utils.filelist_path(config)) / "{label}-{tier}.filelist"),
    script:
        "src/legenddataflow/scripts/write_filelist.py"


rule sort_data:
    """Move DAQ data from sandbox to organized folder.

    This rules moves the DAQ data from the unsorted sandbox directory to the
    correct location in the `tier_raw` folder.
    """
    input:
        patt.get_pattern_tier_daq_unsorted(config),
    output:
        patt.get_pattern_tier_daq(config),
    shell:
        "mv {input} {output}"


use rule sort_data as sort_data_fcio with:
    input:
        patt.get_pattern_tier_daq_unsorted(config, extension="fcio"),
    output:
        patt.get_pattern_tier_daq(config, extension="fcio"),


# vim: filetype=snakemake
