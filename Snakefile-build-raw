"""
Snakefile for doing the first stages of data processing from the daq sandbox files
to the blinded raw data. It handles:
- moving the daq files from the sandbox to the sorted file system
- running build raw on this data (with trimming)
- blinding the physics data
"""

import pathlib, os, json, sys
from scripts.util.patterns import (
    get_pattern_unsorted_data,
    get_pattern_tier_daq,
    get_pattern_tier_raw,
)
from scripts.util.utils import (
    subst_vars_in_snakemake_config,
    runcmd,
    config_path,
    chan_map_path,
    filelist_path,
    pars_path,
    metadata_path,
)
from scripts.util.pars_loading import pars_catalog
import scripts.util as ds


# Set with `snakemake --configfile=/path/to/your/config.json`
# configfile: "have/to/specify/path/to/your/config.json"

subst_vars_in_snakemake_config(workflow, config)

setup = config["setups"]["l200"]
configs = config_path(setup)
chan_maps = chan_map_path(setup)
swenv = runcmd(setup)
meta = metadata_path(setup)

basedir = workflow.basedir


localrules:
    gen_filelist,
    autogen_output,


ds.pars_key_resolve.write_par_catalog(
    ["-*-*-*-cal"],
    os.path.join(pars_path(setup), "raw", "validity.jsonl"),
    [
        get_pattern_unsorted_data(setup),
        get_pattern_tier_daq(setup),
        get_pattern_tier_raw(setup),
    ],
    {"cal": ["par_raw"]},
)


onstart:
    print("Starting workflow")


onsuccess:
    print("Workflow finished, no error")
    shell("rm *.gen || true")
    shell(f"rm {filelist_path(setup)}/* || true")


include: "rules/common.smk"
include: "rules/main.smk"
include: "rules/raw.smk"
include: "rules/blinding_check.smk"


checkpoint gen_filelist:
    """
    This rule generates the filelist. It is a checkpoint so when it is run it will update
    the dag passed on the files it finds as an output. It does this by taking in the search
    pattern, using this to find all the files that match this pattern, deriving the keys from
    the files found and generating the list of new files needed.
    """
    output:
        os.path.join(filelist_path(setup), "{label}-{tier}.{extension}list"),
    params:
        setup=lambda wildcards: setup,
        search_pattern=lambda wildcards: get_pattern(wildcards.tier),
        basedir=basedir,
        configs=configs,
        chan_maps=chan_maps,
        blinding=lambda wildcards: True if wildcards.tier == "raw" else False,
    script:
        "scripts/create_{wildcards.extension}list.py"


rule sort_data:
    """
    This rules moves the daq data from the unsorted sandbox dir
    to the sorted dirs under generated
    """
    input:
        get_pattern_unsorted_data(setup),
    output:
        get_pattern_tier_daq(setup),
    shell:
        "mv {input} {output}"
