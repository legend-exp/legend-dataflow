[build-system]
requires = [
    "setuptools>=61.2",
    "setuptools_scm[toml]>=7"
]
build-backend = "setuptools.build_meta"

[tool.setuptools]
include-package-data = true
zip-safe = false
license-files = [
    "LICENSE.md",
]
py-modules = []

[tool.setuptools.package-dir]
"" = "workflow/src"

[tool.setuptools.packages.find]
where = ["workflow/src"]

[tool.setuptools_scm]
write_to = "workflow/src/legenddataflow/_version.py"

[project]
name = "legend_dataflow"
description = "Python package for processing LEGEND-200 data"
authors = [
    {name = "George Marshall", email = "george.marshall.20@ucl.ac.uk"},
    {name = "Luigi Pertoldi", email = "gipert@pm.me"},
]
maintainers = [
    {name = "The LEGEND Collaboration"},
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Operating System :: MacOS",
    "Operating System :: POSIX",
    "Operating System :: Unix",
    "Programming Language :: Python",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3 :: Only",
    "Topic :: Scientific/Engineering",
]
readme = "README.md"
requires-python = ">=3.11"
dynamic = ["version"]

dependencies = [
    "colorlog",
    "dbetto==1.2.3",
    "pygama==2.1.1a3",
    "dspeed==1.6.6a2",
    "pylegendmeta==1.2.5",
    "legend-pydataobj==1.12.0a4",
    "legend-daq2lh5==1.6.1",
    "legend-dataflow-scripts==0.1.5",
    "pip",
]

#"legend-dataflow-scripts @  file:///${PROJECT_ROOT}/../legend-dataflow-scripts",
# "legend-daq2lh5 @  file:///${PROJECT_ROOT}/software/python/src/legend-daq2lh5
# "pygama @ file:///${PROJECT_ROOT}/software/python/src/pygama",
# "dspeed @ file:///${PROJECT_ROOT}/software/python/src/dspeed",
# "legend-pydataobj @ file:///${PROJECT_ROOT}/software/python/src/legend-pydataobj",

[project.optional-dependencies]
# these are needed to run the data production
runprod = [
    "pygments",
    "snakemake>=8.16",
]
test = [
    "legend_dataflow[runprod]",
    "pytest>=6",
    "pytest-cov>=3",
]
dev = [
    "legend_dataflow[runprod,test]",
    "pre-commit",
]
docs = [
    "sphinx>=7.0",
    "myst_parser>=0.13",
    "sphinx_inline_tabs",
    "sphinx_copybutton",
    "sphinx_autodoc_typehints",
    "furo>=2023.08.17",
]

[project.scripts]
create-chankeylist      = "legenddataflow.scripts.create_chankeylist:create_chankeylist"
merge-channels          = "legenddataflow.scripts.flow.merge_channels:merge_channels"
build-tier-evt          = "legenddataflow.scripts.tier.evt:build_tier_evt"
build-tier-raw-blind    = "legenddataflow.scripts.tier.raw_blind:build_tier_raw_blind"
build-tier-raw-fcio     = "legenddataflow.scripts.tier.raw_fcio:build_tier_raw_fcio"
build-tier-raw-orca     = "legenddataflow.scripts.tier.raw_orca:build_tier_raw_orca"
build-tier-skm          = "legenddataflow.scripts.tier.skm:build_tier_skm"
build-tier-tcm          = "legenddataflow.scripts.tier.tcm:build_tier_tcm"
par-geds-pht-aoe        = "legenddataflow.scripts.par.geds.pht.aoe:par_geds_pht_aoe"
par-geds-pht-ecal-part  = "legenddataflow.scripts.par.geds.pht.ecal_part:par_geds_pht_ecal_part"
par-geds-pht-fast       = "legenddataflow.scripts.par.geds.pht.fast:par_geds_pht_fast"
par-geds-pht-qc-phy     = "legenddataflow.scripts.par.geds.pht.qc_phy:par_geds_pht_qc_phy"
par-geds-pht-qc         = "legenddataflow.scripts.par.geds.pht.qc:par_geds_pht_qc"
par-geds-psp-average    = "legenddataflow.scripts.par.geds.psp.average:par_geds_psp_average"
par-geds-raw-blindcal   = "legenddataflow.scripts.par.geds.raw.blindcal:par_geds_raw_blindcal"
par-geds-raw-blindcheck = "legenddataflow.scripts.par.geds.raw.blindcheck:par_geds_raw_blindcheck"
par-geds-tcm-pulser     = "legenddataflow.scripts.par.geds.tcm.pulser:par_geds_tcm_pulser"
par-spms-dsp-trg-thr    = "legenddataflow.scripts.par.spms.dsp.trigger_threshold:par_spms_dsp_trg_thr"
par-spms-dsp-trg-thr-multi    = "legenddataflow.scripts.par.spms.dsp.trigger_threshold:par_spms_dsp_trg_thr_multi"

[tool.uv.workspace]
exclude = ["generated", "inputs", "software", "workflow"]

[tool.uv]
default-groups = []

[tool.pytest.ini_options]
minversion = "6.0"
addopts = ["-ra", "--showlocals", "--strict-markers", "--strict-config"]
xfail_strict = true
filterwarnings = [
  "error",
]
log_cli_level = "INFO"
testpaths = [
  "tests",
]

[tool.ruff]
src = ["workflow/src"]

[tool.ruff.lint]
extend-select = [
  "ARG",      # flake8-unused-arguments
  "B",        # flake8-bugbear
  "C4",       # flake8-comprehensions
  "EM",       # flake8-errmsg
  "EXE",      # flake8-executable
  "G",        # flake8-logging-format
  "I",        # isort
  "ICN",      # flake8-import-conventions
  "NPY",      # NumPy specific rules
  "PD",       # pandas-vet
  "PGH",      # pygrep-hooks
  "PIE",      # flake8-pie
  "PL",       # pylint
  "PT",       # flake8-pytest-style
  "PTH",      # flake8-use-pathlib
  "RET",      # flake8-return
  "RUF",      # Ruff-specific
  "SIM",      # flake8-simplify
  "T20",      # flake8-print
  "UP",       # pyupgrade
  "YTT",      # flake8-2020
]
ignore = [
  "PT011",    # `pytest.raises(ValueError)` is too broad
  "PLR09",    # Too many <...>
  "PLR2004",  # Magic value used in comparison
  "ISC001",   # Conflicts with formatter
]
isort.required-imports = ["from __future__ import annotations"]

[tool.ruff.lint.per-file-ignores]
"tests/**" = ["T20"]
"noxfile.py" = ["T20"]


[tool.pylint]
py-version = "3.9"
ignore-paths = [".*/_version.py"]
reports.output-format = "colorized"
similarities.ignore-imports = "yes"
messages_control.disable = [
  "design",
  "fixme",
  "line-too-long",
  "missing-module-docstring",
  "missing-function-docstring",
  "wrong-import-position",
  "too-many-nested-blocks"
]
